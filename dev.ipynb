{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8cc6a-4409-4f9a-beaa-761a0de6c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "import chromadb\n",
    "import langchain\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import LLMChain, RetrievalQA, create_tagging_chain_pydantic\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import RedisChatMessageHistory, ConversationBufferWindowMemory\n",
    "from langchain.retrievers.merger_retriever import MergerRetriever\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.storage import LocalFileStore, RedisStore\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.vectorstores import Chroma\n",
    "import redis\n",
    "import spacy\n",
    "\n",
    "from core.llm_wrapers import *\n",
    "from core.tool_functions import *\n",
    "from core.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acd069-612d-497f-b148-75213068ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_HOST = \"redis\"\n",
    "CHROMA_HOST = \"chroma\"\n",
    "CHROMA_PERSIST_DIRECTORY = \"/chroma\"\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "KNOWLEDGE_BASE_DIR = \"./knowledge_base\"\n",
    "\n",
    "RETRIEVER_COLLECTION_SETTINGS = {\n",
    "    \"info\": [{\"name\": \"bm25\", \"k\": 1, \"score_threshold\": 0.35}, {\"name\": \"semantic\", \"k\": 3, \"score_threshold\": 0.35}],\n",
    "    \"links\": [{\"name\": \"semantic\", \"k\": 1}]\n",
    "}\n",
    "\n",
    "CREATE_DATABASE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79735de-0dab-4592-9255-4845e97a298b",
   "metadata": {},
   "source": [
    "Initialize cache vectordb for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ed74f-6a9b-4d55-a9f7-c82a0e682dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_emb_client = chromadb.HttpClient(host=CHROMA_HOST, port=8000)\n",
    "chroma_emb_client._settings.is_persistent = True\n",
    "chroma_emb_client._settings.persist_directory=CHROMA_PERSIST_DIRECTORY\n",
    "\n",
    "redis_emb_client = redis.Redis(host=REDIS_HOST, port=6379, db=0)\n",
    "redis_emb_store = RedisStore(client=redis_emb_client, namespace=EMBEDDING_MODEL)\n",
    "\n",
    "cached_embedder = CachedEmbeddings.from_bytes_store(OpenAIEmbeddings(model=EMBEDDING_MODEL), redis_emb_store, namespace=EMBEDDING_MODEL)\n",
    "\n",
    "if CREATE_DATABASE:\n",
    "    collection_names = create_knowledge_vectordb(KNOWLEDGE_BASE_DIR, cached_embedder,  chroma_emb_client, CHROMA_PERSIST_DIRECTORY)\n",
    "    print(collection_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10b1e8-3e4c-4ec5-87b2-9328f31d0363",
   "metadata": {},
   "source": [
    "Initialize relative documents (context) retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ccd78-a53a-4a7a-b939-a6c5df52b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load(\"uk_core_news_sm\")\n",
    "\n",
    "retrievers = []\n",
    "for collection_name, collection_config in RETRIEVER_COLLECTION_SETTINGS.items():\n",
    "    collection_retrievers = []\n",
    "\n",
    "    for retriever_info in collection_config:\n",
    "        if retriever_info[\"name\"] == \"bm25\":\n",
    "            collection_texts = load_texts(os.path.join(KNOWLEDGE_BASE_DIR, collection_name))\n",
    "            bm25 = BM25Retriever.from_texts(collection_texts, preprocess_func=lambda x: [token.lemma_ for token in spacy_nlp(x)], **retriever_info)\n",
    "            collection_retrievers.append(bm25)\n",
    "        elif retriever_info[\"name\"] == \"semantic\":\n",
    "            collection_db = Chroma(embedding_function=cached_embedder, collection_name=collection_name,\n",
    "                                   client=chroma_emb_client, persist_directory=CHROMA_PERSIST_DIRECTORY)\n",
    "            semantic_retriever = collection_db.as_retriever(search_type=\"similarity\", search_kwargs=retriever_info)\n",
    "            collection_retrievers.append(semantic_retriever)\n",
    "\n",
    "    if len(collection_retrievers) > 1:\n",
    "        retrievers.append(EnsembleRetriever(retrievers=collection_retrievers))\n",
    "    else:\n",
    "        retrievers.append(collection_retrievers[0])\n",
    "\n",
    "context_retriever = MergerRetriever(retrievers=retrievers) if len(retrievers) > 1 else retrievers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754795e-fe3b-4091-aa2f-65d10662f8a8",
   "metadata": {},
   "source": [
    "Initialize RetrievalQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb8859-3625-4512-9f74-3914fd846483",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", verbose=True)\n",
    "\n",
    "\n",
    "rqa_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        template=(\"You are an AI assistant who answers customer questions about the services and processes \"\n",
    "                  \"of the postal company Nova Poshta. Use the following pieces of context to answer the question. \"\n",
    "                  \"Answer only in Ukrainian, regardless of the question language.\\n\\nCONTEXT:\\n{context}\\n\\n\"\n",
    "                  \"USER QUESTION: {question}\\n\\n\"\n",
    "                  \"If the question is not related to the context, tell to contact the support. If the answer is not \"\n",
    "                  \"contained in the context, tell to contact support. Don't make up the answer. If the question is not \"\n",
    "                  \"related to the postal services or it doesn't make sense, tell that you can't answer it.\\n\\n\"\n",
    "                  \"ANSWER IN UKRAINIAN:'\")\n",
    "    )]\n",
    ")\n",
    "rqa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=context_retriever, return_source_documents=True,\n",
    "                                        chain_type_kwargs={\"prompt\": rqa_prompt_template})\n",
    "\n",
    "\n",
    "condense_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        template=(\"You are an AI assistant who answers customer questions about the services and processes \"\n",
    "                  \"of the postal company Nova Poshta. Given the following conversation and a follow user up input, \"\n",
    "                  \"rephrase it to be a standalone question.\"\n",
    "                  \"\\n\\nLast Messages:\\n{last_messages}\\n\\nHuman Follow Up Input: {question}\\n\\n\"\n",
    "                  \"If the follow up user input is not related to the last messages, return it as it is.\\n\"\n",
    "                  \"REPHRASED QUESTION IN UKRAINIAN:\")\n",
    "    )]\n",
    ")\n",
    "condense_chain = LLMChain(llm=llm, prompt=condense_prompt_template)\n",
    "\n",
    "\n",
    "chroma_questions_db = Chroma(embedding_function=cached_embedder, collection_name=\"questionss\",\n",
    "                             client=chroma_emb_client, persist_directory=CHROMA_PERSIST_DIRECTORY)\n",
    "redis_qa_client = redis.Redis(host=REDIS_HOST, port=6379, db=3)\n",
    "rqa_cache = CompletionCache(chroma_questions_db, redis_qa_client)\n",
    "cached_conversational_rqa = CachedConversationalRQA(condense_chain, rqa_chain, rqa_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a67b59-2ad4-407c-a72a-3f6c824e3994",
   "metadata": {},
   "source": [
    "Initialize OpenAI functions agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff28fe-9b07-41bb-8026-03c410670603",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"package_info\",\n",
    "        func=get_package_info,\n",
    "        args_schema=Package,\n",
    "        description=\"Useful for when you need to get tracking details and other information about the package\",\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=calculate_delivery_cost,\n",
    "        args_schema=DeliveryCost,\n",
    "        description=\"Useful for when you need to estimate the delivery cost\"\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=estimate_delivery_date,\n",
    "        args_schema=DeliveryDetails,\n",
    "        description=\"Useful for when you need to estimate package delivery date\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"question_answering\",\n",
    "        func=lambda question: cached_conversational_rqa(question, []),\n",
    "        args_schema=Question,\n",
    "        description=\"Useful for answering any type of questions, always use it if user asks a question\",\n",
    "        return_direct=True\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        template=(\"You are an AI assistant of the postal company Nova Poshta, which performs basic operations: \"\n",
    "                  \"tracking parcels, calculating service costs, and informing about delivery terms. \"\n",
    "                  \"You can also answer questions about the services and processes of the company.\"\n",
    "                  \"If the question is not related to the Nova Poshta or it doesn't make sense, tell that you can't answer it.\\n{chat_messages}\")\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        template=\"{input}\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        template=\"Do not answer the questions that are not related to the postal, logistics, delivery, courier and related services and processes.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ]\n",
    ")\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, llm_prompt=agent_prompt_template, verbose=False)\n",
    "agent.agent.prompt = agent_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0d738-f9ce-48a0-92f8-c28747d687c5",
   "metadata": {},
   "source": [
    "Test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226149e-9648-4bdb-a01b-d76e2eb7069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"42\"\n",
    "\n",
    "chat_history = RedisChatMessageHistory(session_id=session_id, url=f\"redis://{REDIS_HOST}:6379/2\")\n",
    "chat_history.clear()\n",
    "\n",
    "chat_handler = LLMChatHandler(agent, chat_history)\n",
    "\n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f2491-c23c-4477-92d1-74fc5a05f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Привіт\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290444e-8b7b-44e1-9231-7960257f0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Хочу дізнатись статус відправлення\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776fdae-9e28-477f-9fc9-c09b3b912be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"20700476898586\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff98db-0774-4072-a666-7acea0c6b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Що таке обрешетування\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e981ff8-9906-433f-aafa-7c1c7cbe3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Допоможи розрахувати вартість доставки\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f7358-6530-4230-a7f4-0f24a9e49f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Вага - 10 кг, 40х20х30см\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631073cf-c906-4468-8e17-279c5f8ef8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Оголошена вартість - 1000 грн\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058aa6c4-a386-4a95-a662-4a0ef2ade1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"Як дізнатись приблизну дату доставки\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3d563-7abc-4104-92ff-af62272c1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_handler.send_message(\"20.08.2023, Київ-Львів\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
